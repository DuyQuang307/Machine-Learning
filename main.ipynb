import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
# Array
import numpy as np

# Dataframe
import pandas as pd

# Visualization
import matplotlib.pyplot as plt
import seaborn as sns

# Data preprocessing
from sklearn.preprocessing import LabelEncoder,RobustScaler
from sklearn.model_selection import train_test_split,StratifiedKFold,GridSearchCV,cross_val_score,cross_val_predict

# ML models
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier

# DL model
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, BatchNormalization, Dropout
from tensorflow.keras.optimizers import Adam

#Model Evaluation
from sklearn.metrics import accuracy_score,f1_score,confusion_matrix,classification_report

#Pipeline
from sklearn.pipeline import Pipeline

# Warnings
import warnings
warnings.filterwarnings('ignore')
# Data Info
hotel.info()
cat=hotel.select_dtypes(exclude=[np.number])

for i in cat.columns:
    hotel[i]=hotel[i].astype('category')

# Data Info
hotel.info()
hotel.describe()
# Data Labelencoding
for i in cat.columns:
    hotel[i+"_encoder"]=LabelEncoder().fit_transform(hotel[i])

# Taking numerical values
num=hotel.select_dtypes(include=[np.number])

#Selecting features & target variable
x=num.drop('booking_status_encoder',axis=1)
y=num['booking_status_encoder']

#Data Scaling
x=pd.DataFrame(RobustScaler().fit_transform(x.to_numpy()),columns=x.columns)

#Scaled data
x.head()
data=x.join(y)

# Final scaled Data
data.head()
# Data Spliting into training & testing
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=42)
mdl_lr(x_train,x_test,y_train,y_test)
mdl_nb(x_train,x_test,y_train,y_test)
mdl_rf(x_train,x_test,y_train,y_test)
mdl_xgb(x_train,x_test,y_train,y_test)
# MOdel Evaluation Tabular Format
tbl=pd.DataFrame()
tbl['Model']=['Logistic Regression','Naive Bayes','Random Forest']
tbl['Training Accuracy']=[acc_trn_lr,acc_trn_nb,acc_trn_rf]
tbl['Testing Accuracy']=[acc_lr,acc_nb,acc_rf]
tbl['F1 Score']=[f1_lr,f1_nb,f1_rf]

tbl.sort_values('F1 Score',ascending=False,ignore_index=True)
# Applying Cross Validation to Avoid Overfitting - Accuracy Score
lr=LogisticRegression()
nb=GaussianNB()
rf=RandomForestClassifier(random_state=10)

result=[]

m=[lr,nb,rf]
mdl_name=['Logistic Regression','Naive Bayes','Random Forest']

def mdl(model):
    print("\n")
    print(i)
    pipe=Pipeline([('model',model)])
    pipe.fit(x_train,y_train)
    cv=StratifiedKFold(n_splits=5)
    scr=cross_val_score(pipe,x_train,y_train,cv=cv,scoring='accuracy',n_jobs=-1)
    result.append(scr)
    y_pred=cross_val_predict(model,x_train,y_train,cv=cv)
    acc=accuracy_score(y_train,y_pred)
    print("Training Accuracy: ",np.mean(scr))
    print("Testing Accuracy: ",acc)

for i in m:
    mdl(i)

plt.figure(figsize=(10,8),layout='constrained')
plt.title('Model Evaluation by Cross Validation Method')
plt.xlabel('Models')
plt.ylabel('Accuracy Score')
plt.boxplot(result,labels=mdl_name,showmeans=True)
plt.show()
# Trực quan hóa dữ liệu
num_sut = 3
num_sat = len(hotel.columns) // num_sut + (len(hotel.columns) % num_sut > 0)
renkler=['#FF91A4','#C0C0C0']
fig, eksn = plt.subplots(num_sat, num_sut, figsize=(12, 8))
# Sử dụng value_counts() để đếm số lần xuất hiện của mỗi giá trị trong cột và vẽ bar chat
for i, column in enumerate(hotel.columns):
    ax = eksn[i // num_sut, i % num_sut]
    hotel[column].value_counts().plot(kind='bar', ax=ax, color=renkler)
    ax.set_title(f'{column}')

# nếu có dư số cột sau khi vòng lặp đã chạy xong, các cột đó sẽ bị gỡ bỏ (delaxes)
for i in range(len(hotel.columns), num_sut * num_sat):
    fig.delaxes(eksn[i // num_sut, i % num_sut])

plt.tight_layout()
plt.show()
# Applying Cross Validation to Avoid Overfitting - F1 Score
lr=LogisticRegression()
nb=GaussianNB()
rf=RandomForestClassifier(random_state=10)

result=[]

m=[lr,nb,rf]
mdl_name=['Logistic Regression','Naive Bayes','Random Forest']

def mdl(model):
    print("\n")
    print(i)
    pipe=Pipeline([('model',model)])
    pipe.fit(x_train,y_train)
    cv=StratifiedKFold(n_splits=5)
    scr=cross_val_score(pipe,x_train,y_train,cv=cv,scoring='f1_weighted',n_jobs=-1)
    result.append(scr)
    y_pred=cross_val_predict(model,x_train,y_train,cv=cv)
    f1=f1_score(y_train,y_pred)
    print("Training F1: ",np.mean(scr))
    print("Testing F1: ",f1)

for i in m:
    mdl(i)

plt.figure(figsize=(10,8),layout='constrained')
plt.title('Model Evaluation by Cross Validation Method')
plt.xlabel('Models')
plt.ylabel('F1 Score')
plt.boxplot(result,labels=mdl_name,showmeans=True)
plt.show()
# DL Model
dl_model = Sequential([keras.layers.Dense(256, activation = "relu",input_shape = [18]),
                       keras.layers.Dropout(0.3),
                       keras.layers.Dense(256, activation = "relu"),
                       keras.layers.Dropout(0.3),
                       keras.layers.Dense(256, activation = "relu"),
                       keras.layers.Dropout(0.3),
                       keras.layers.Dense(1, activation="sigmoid")])

# Model Compilation
dl_model.compile(optimizer='Adam',loss='binary_crossentropy', metrics = ['accuracy'])

# Model Fit
result=dl_model.fit(x_train,y_train,
                    validation_data=(x_test,y_test),
                    batch_size=256,
                    epochs=500)
# Model Evaluation
dl_eval=dl_model.evaluate(x,y)
print("\n")
print("***************Deep Learning Model Evaluation******************")
print("\n")
print("Accuracy : ",dl_eval[1])
print("Loss : ",dl_eval[0])
